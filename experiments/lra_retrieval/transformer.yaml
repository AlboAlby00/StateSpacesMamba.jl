# total params: 1987139
# model params
model_name: transformer
dataset: lra_retrieval

embed_dim: 128
n_layers: 4
qk_dim: 128
v_dim: 128
n_heads: 4
n_hidden: 512

# other hyperparameters
data_to_use_percent: 1.0
train_batch_size: 32
validation_batch_size: 32

seq_len: 4000
initial_lr: 0.05
init_fin_lr_ratio: 0.1

save_csv: true
save_model: true

num_iterations: 1
num_epochs: 10