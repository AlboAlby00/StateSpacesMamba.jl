# model params
model_name: transformer
embed_dim: 256
n_layers: 3
dropout: 0.1
# other hyperparameters
data_to_use_percent: 0.2
train_batch_size: 64
test_batch_size: 64
seq_len: 256
initial_lr: 1e-4
final_lr: 1e-5
save_csv: true
save_model: true

num_epochs: 20
num_iterations: 2