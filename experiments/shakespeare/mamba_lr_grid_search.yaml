# total params: 1987139
# model params
model_name: mamba
dataset: shakespeare

embed_dim: 128
N: 16
n_layers: 6
dropout: 0.0
ssm_dropout: 0.0
# other hyperparameters
data_to_use_percent: 1.0
train_batch_size: 64
test_batch_size: 64
seq_len: 256
initial_lr: [1e-2, 1e-3, 1e-4]
init_fin_lr_ratio: 0.1

num_epochs: 100
num_iterations: 2

save_csv: false
save_model: false

use_A_dropout: true