# model params
model_name: mamba
dataset: shakespeare

embed_dim: 128
N: 8
n_layers: 3
dropout: 0.1
ssm_dropout: 0.1
# other hyperparameters
data_to_use_percent: 0.2
train_batch_size: 32
test_batch_size: 32
seq_len: 256
initial_lr: 1e-3
init_fin_lr_ratio: 0.1

save_csv: true
save_model: true

num_epochs: 100
num_iterations: 3
use_A_dropout: [false, true]